{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b94f5773b040af7dc8a748e0d2eea78911fa52ee",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nprint(tf.test.gpu_device_name())\n# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0589806fd6665c5a917f0997c51bb33d0e989a66",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input/data/data\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a36bc26ae76d7090da7d16b84cef20072dd6a76a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\nimport numpy as np \nimport os\nimport glob\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as keras\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d0bde0547f98961ee8c49e0c59a866a14d463a80"
      },
      "cell_type": "code",
      "source": "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n\nimg_rows = 512\nimg_cols = 640\n\nsmooth = 1.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8f1be05950d9e9f39d8efd411f699beacb4662b5"
      },
      "cell_type": "code",
      "source": "def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\n\ndef Specificity(y_true, y_pred):\n    true_negatives = K.abs(y_pred)- K.abs(y_true)\n    return ((true_negatives+smooth)/(y_pred+ smooth))\n\ndef Sensitivity(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    return ((y_pred+smooth)/ (y_true+smooth))\n\ndef Jaccard_index(y_true,y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return ((intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "db432f201a0098edb18a59a7ea2c1d8370387747"
      },
      "cell_type": "code",
      "source": "background_tissue = [0,0,0]\ninstrument_shaft = [0,255,0]\ninstrument_clasper = [0,255,255]\ninstrument_wrist = [125,255,12]\nkidney_parenchyma = [255,55,0]\ncovered_kidney = [24,55,125]\nthread = [187,155,25]\nclamps = [ 0,255,125]\nsuturing_needle = [255,255,125]\nsuction_instrument = [123,15,175]\nsmall_intestine = [124,155,5]\nultrasound_probe = [12,255,141]\n\nCOLOR_DICT = np.array([background_tissue,instrument_shaft, instrument_clasper, instrument_wrist, kidney_parenchyma,\n                          covered_kidney, thread, clamps, suturing_needle, suction_instrument, small_intestine, ultrasound_probe])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9002d869e4422a011dde9de042f200d2519a83c9"
      },
      "cell_type": "code",
      "source": "def adjustData(img,mask,flag_multi_class,num_class):\n    if(flag_multi_class):\n        img = img / 255\n        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n        new_mask = np.zeros(mask.shape + (num_class,))\n        for i in range(num_class):\n            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n            #index = np.where(mask == i)\n            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n            #new_mask[index_mask] = 1\n            new_mask[mask == i,i] = 1\n        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n        mask = new_mask\n    elif(np.max(img) > 1):\n        img = img / 255\n        mask = mask /255\n        mask[mask > 0.5] = 1\n        mask[mask <= 0.5] = 0\n    return (img,mask)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "3cafe6677cbd27afafccb4c1e4941b5b7262f5b2"
      },
      "cell_type": "code",
      "source": "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (512,640),seed = 1):\n    '''\n    can generate image and mask at the same time\n    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n    '''\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    image_generator = image_datagen.flow_from_directory(\n        train_path,\n        classes = [image_folder],\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n    mask_generator = mask_datagen.flow_from_directory(\n        train_path,\n        classes = [mask_folder],\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n    train_generator = zip(image_generator, mask_generator)\n    for (img,mask) in train_generator:\n        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n        yield (img,mask)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4d6dc2881196b5f2bd81356bbc713e7093740785"
      },
      "cell_type": "code",
      "source": "def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n    for i in range(num_image):\n        img = io.imread(os.path.join(test_path,\"%d.png\"%i),as_gray = as_gray)\n        img = img / 255\n        img = trans.resize(img,target_size)\n        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n        img = np.reshape(img,(1,)+img.shape)\n        yield img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0ada56f05077b431d277dcdc3c4029bd1c1da685"
      },
      "cell_type": "code",
      "source": "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.png\"%image_prefix))\n    image_arr = []\n    mask_arr = []\n    for index,item in enumerate(image_name_arr):\n        img = io.imread(item,as_gray = image_as_gray)\n        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n        image_arr.append(img)\n        mask_arr.append(mask)\n    image_arr = np.array(image_arr)\n    mask_arr = np.array(mask_arr)\n    return image_arr,mask_arr",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "6324e7de93231613ec185a7565d5f4e3fe7b1f79"
      },
      "cell_type": "code",
      "source": "def labelVisualize(num_class,color_dict,img):\n    img = img[:,:,0] if len(img.shape) == 3 else img\n    img_out = np.zeros(img.shape + (3,))\n    for i in range(num_class):\n        img_out[img == i,:] = color_dict[i]\n    return img_out / 255",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e52f6941d4588d8c6757ad5176d5b6f254b2c449"
      },
      "cell_type": "code",
      "source": "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n    for i,item in enumerate(npyfile):\n        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d170c1474a8533813fb5b65eda56fbbe7c0b1f87"
      },
      "cell_type": "code",
      "source": "def unet():\n    inputs = Input((img_rows, img_cols, 1))\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    model = Model(inputs=[inputs], outputs=[conv10])\n\n    model.compile(optimizer=Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), loss=dice_coef_loss, metrics=[dice_coef, 'acc',Jaccard_index, Specificity, Sensitivity])\n\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b714dfb91153bc04b275b24ba1d49f5d4f47855b"
      },
      "cell_type": "code",
      "source": "data_gen_args = dict(rotation_range=0.2,\n                    width_shift_range=0.05,\n                    height_shift_range=0.05,\n                    shear_range=0.05,\n                    zoom_range=0.05,\n                    horizontal_flip=True,\n                    fill_mode='nearest')\ntrain_generator = trainGenerator(8,'../input/data/data/training','images','masks',data_gen_args,save_to_dir = None)\nvalidation_generator = trainGenerator(8,'../input/data/data/validation','images','masks',data_gen_args,save_to_dir = None)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f2565e8589898363818d57573dd4ef1a4e376d21"
      },
      "cell_type": "code",
      "source": "model = unet()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "442de8edef3c688c8fefd1a93226c8d09ba8b905"
      },
      "cell_type": "code",
      "source": "model_checkpoint = ModelCheckpoint('unet_endovis.hdf5', monitor='loss',verbose=1, save_best_only=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "697117cc411a4f43636ae01cb3e49408bb37c1c6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print('Fitting model...')\nprint('-'*30)\nhistory = model.fit_generator(train_generator, nb_epoch=25, verbose=1, shuffle=True,\n          steps_per_epoch= 400,\n          validation_data = validation_generator,\n          validation_steps=100,\n          callbacks=[model_checkpoint])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "0d4dbd514257d4dac990dd3aa738aceee8e843d5"
      },
      "cell_type": "code",
      "source": "score = model.evaluate_generator(validation_generator, steps=50)\n\nprint ('Test Score: ', score[0])\nprint ('Test Accuracy: ',score[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e5a32e20bc01581a2c9d8e71efe6aa96bbb3b6f7"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "098e286016ad7f4b0742d280320d42d8d02524c1"
      },
      "cell_type": "code",
      "source": "acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c42eedad7631b667a3e874de84cc4ad4a9dad935"
      },
      "cell_type": "code",
      "source": "import numpy as np\nplt.figure(1)\nplt.plot(history.history['loss'],'r')\nplt.plot(history.history['val_loss'],'g')\n\nplt.rcParams['figure.figsize'] = (8, 6)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Validation Loss\")\nplt.legend(['train','validation'])\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d55af104c3cda84839bcb5fe7137f56ec4eab900"
      },
      "cell_type": "code",
      "source": "filename = validation_generator.filenames\ntruth = validation_generator.classes\nlabel = validation_generator.class_indices\nindexlabel = dict((value, key) for key, value in label.items())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e2eda945838e78e269d62844bd32c30f90371bd3"
      },
      "cell_type": "code",
      "source": "filename = validation_generator.filenames\ntruth = validation_generator.classes\nlabel = validation_generator.class_indices\nindexlabel = dict((value, key) for key, value in label.items())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "85bca525ff3cd07791e11ca280df6ec6649739f3"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(truth,predict_class)\n\nlabels = []\nfor k,v in indexlabel.items():\n    labels.append(v)\n    \nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, classes=labels,\n                      title='Confusion matrix')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ad4457f10eabd47457fe6cd557542960ebb7cee2"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(truth,predict_class)\n\nlabels = []\nfor k,v in indexlabel.items():\n    labels.append(v)\n    \nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, classes=labels,\n                      title='Confusion matrix')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "79c496bb5291a5a0275a22211e1ed3368a22e043"
      },
      "cell_type": "code",
      "source": "predict_and_report(train_generator, model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d7d2ade44180e518bf2454e99988216bf67e765d"
      },
      "cell_type": "code",
      "source": "predict_and_report(validation_generator, model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1bc9eb70cf7b49266b380ec9762ed17968e0752c"
      },
      "cell_type": "code",
      "source": "best_train_acc = max(history.history['acc'])\nbest_train_acc",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "79d1c6f88ac6fc267683e7296071cbfeefdbb255"
      },
      "cell_type": "code",
      "source": "best_train_acc = max(history.history['acc'])\nbest_train_acc",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "9853e4d8b61937c38f3c3e6e498c3b5ebe622ecd"
      },
      "cell_type": "code",
      "source": "model.save('EndoVis-Unet-Model.h5')\nmodel.save_weights('EndoVis-Unet-Weights.h5')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "d101708934e01d3a57ec751c2216d3234b2d40cd"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "738b27f2bda6a818a4973442f21dc56fe9765efe"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1521cb0222590b04c86ef2d67383f8abca562630"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
